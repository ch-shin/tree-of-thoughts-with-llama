{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2997142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: OPENAI_API_KEY is not set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/changho/cshin/miniconda3/envs/wscot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import argparse\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "from models import gpt, gpt_usage\n",
    "# from model_llama import llama, llama_usage\n",
    "import model_llama\n",
    "from tasks import get_task # get_task is a function defined in tasks/__init__.py, where it imports a task class from e.g.: tasks/text.py and calls a constructor for that class to create an object, and returns it. \n",
    "from run import get_value, get_values, get_votes, get_proposals, get_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68603db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 6.35 s, total: 1min 46s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Replaced with llama\n",
    "global LLM \n",
    "\n",
    "# load llama --- it can take a few minutes\n",
    "LLM = model_llama.LLM(model_name='llama-7B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6fbaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(task, x, y, n_evaluate_sample, cache_value=True):\n",
    "    # breakpoint()\n",
    "    value_prompt = task.value_prompt_wrap(x, y)\n",
    "\n",
    "    if cache_value and value_prompt in task.value_cache:\n",
    "        return task.value_cache[value_prompt]\n",
    "    # value_outputs = gpt(value_prompt, n=n_evaluate_sample, stop=None)\n",
    "\n",
    "    # Replaced with llama\n",
    "    value_outputs = LLM.llama(value_prompt, max_tokens = 100, do_sample = False, beams = n_evaluate_sample, n= n_evaluate_sample)\n",
    "\n",
    "    value = task.value_outputs_unwrap(x, y, value_outputs)\n",
    "    if cache_value:\n",
    "        task.value_cache[value_prompt] = value\n",
    "\n",
    "    return value\n",
    "\n",
    "def get_values(task, x, ys, n_evaluate_sample, cache_value=True):\n",
    "    # breakpoint()\n",
    "    values = []\n",
    "    local_value_cache = {}\n",
    "    for y in ys:  # each partial output\n",
    "        # breakpoint()\n",
    "        if y in local_value_cache:  # avoid duplicate candidates\n",
    "            value = 0\n",
    "        else:    \n",
    "            value = get_value(task, x, y, n_evaluate_sample, cache_value=cache_value)\n",
    "            \n",
    "            local_value_cache[y] = value\n",
    "        values.append(value)\n",
    "    return values\n",
    "\n",
    "def get_votes(task, x, ys, n_evaluate_sample):\n",
    "    # breakpoint()\n",
    "    vote_prompt = task.vote_prompt_wrap(x, ys)\n",
    "    # vote_outputs = gpt(vote_prompt, n=n_evaluate_sample, stop=None)\n",
    "\n",
    "    # Replaced with llama\n",
    "    vote_outputs = LLM.llama(vote_prompt, max_tokens = 100, do_sample = False, beams = n_evaluate_sample, n = n_evaluate_sample)\n",
    "\n",
    "\n",
    "    values = task.vote_outputs_unwrap(vote_outputs, len(ys))\n",
    "\n",
    "    return values\n",
    "\n",
    "def get_proposals(task, x, y): \n",
    "    # breakpoint()\n",
    "    propose_prompt = task.propose_prompt_wrap(x, y) \n",
    "    # proposals = gpt(propose_prompt, n=1, stop=None)[0].split('\\n')\n",
    "\n",
    "    # Replaced with llama\n",
    "    proposals = LLM.llama(propose_prompt, max_tokens = 100, do_sample = False, beams = 1, n= 1)[0].split('\\n')\n",
    "\n",
    "    return [y + _ + '\\n' for _ in proposals]\n",
    "\n",
    "# Use wrapped prompts to generate new samples from LLM\n",
    "# TODO: add support for other sampling methods\n",
    "def get_samples(task, x, y, n_generate_sample, prompt_sample, stop):\n",
    "    # breakpoint()\n",
    "    if prompt_sample == 'standard':\n",
    "        prompt = task.standard_prompt_wrap(x, y)\n",
    "    elif prompt_sample == 'cot':\n",
    "        prompt = task.cot_prompt_wrap(x, y)\n",
    "    else:\n",
    "        raise ValueError(f'prompt_sample {prompt_sample} not recognized')\n",
    "    # samples = gpt(prompt, n=n_generate_sample, stop=stop)\n",
    "\n",
    "    # Replaced with llama\n",
    "    samples = LLM.llama(prompt, max_tokens = 100, do_sample = False, beams = n_generate_sample, n = n_generate_sample)\n",
    "\n",
    "    return [y + _ for _ in samples]\n",
    "\n",
    "def solve(method_generate, n_generate_sample,\n",
    "          prompt_sample, method_evaluate,\n",
    "          method_select, n_select_sample,\n",
    "          task, idx, to_print=True):\n",
    "    x = task.get_input(idx)  # p: '4 5 6 10' - from 24.csv, read as a pandas frame, extracting 'Puzzles' column, and then indexing into the 900th puzzle\n",
    "    ys = [''] \n",
    "    infos = []\n",
    "\n",
    "    # Breadth of tree in bfs ToT is set using cli: --n_generate_sample\n",
    "    # Height of tree in ToT is set using task.steps in their respective tasks/{file}.py files\n",
    "    for step in range(task.steps): # p: (task.steps = 4 for game24.py) - Set manually in task/{files}.py - e.g., task.steps for game24.py is 4 for 4 operations; text.py is 2.; crossword.py is 10 steps.\n",
    "        # breakpoint()\n",
    "        # generation\n",
    "        if method_generate == 'sample':\n",
    "            new_ys = [get_samples(task, x, y, n_generate_sample, prompt_sample=prompt_sample, stop=task.stops[step]) for y in ys]\n",
    "        elif method_generate == 'propose':\n",
    "            new_ys = [get_proposals(task, x, y) for y in ys]\n",
    "        new_ys = list(itertools.chain(*new_ys)) # itertools.chain takes iterables and convert to one iterable\n",
    "        ids = list(range(len(new_ys)))\n",
    "        # breakpoint()\n",
    "        # evaluation\n",
    "        if method_evaluate == 'vote':\n",
    "            values = get_votes(task, x, new_ys, n_evaluate_sample)\n",
    "        elif method_evaluate == 'value':\n",
    "            values = get_values(task, x, new_ys, n_evaluate_sample)\n",
    "\n",
    "        # breakpoint()\n",
    "        # selection - bfs/ dfs are greedy - essentially, based on the values in evaluation, \n",
    "        # For greedy, we select the top n_select_sample \n",
    "        # For sample, we select n_select_sample based on the probability distribution of the values, \n",
    "        # where we fix the size of output: because 'size' argument is the output shape of random samples of numpy array.\n",
    "        if method_select == 'sample':\n",
    "            ps = np.array(values) / sum(values) # Convert 'values' assigned to each response to probability distribution\n",
    "            select_ids = np.random.choice(ids, size=n_select_sample, p=ps).tolist() # Randomly select n_select_sample for each ys identified by their ids, based on the probability distribution ps (which corresponds to each id/ ys)\n",
    "        elif method_select == 'greedy':\n",
    "            select_ids = sorted(ids, key=lambda x: values[x], reverse=True)[:n_select_sample]\n",
    "        select_new_ys = [new_ys[select_id] for select_id in select_ids] # using the filtered identifier ids (select_ids), select the corresponding new_ys, and assign to select_new_ys\n",
    "\n",
    "        # breakpoint()\n",
    "        # log\n",
    "        if to_print: \n",
    "            # Sort the values and new_ys based on the values\n",
    "            sorted_new_ys, sorted_values = zip(*sorted(zip(new_ys, values), key=lambda x: x[1], reverse=True))\n",
    "            print(f'-- new_ys --: {sorted_new_ys}\\n-- sol values --: {sorted_values}\\n-- choices --: {select_new_ys}\\n')\n",
    "\n",
    "        # Append the information of each step to the json file \n",
    "        infos.append({'step': step, 'x': x, 'ys': ys, 'new_ys': new_ys, 'values': values, 'select_new_ys': select_new_ys})\n",
    "        ys = select_new_ys\n",
    "    \n",
    "    # breakpoint()\n",
    "    if to_print: \n",
    "        print(ys)\n",
    "\n",
    "    return ys, {'steps': infos}\n",
    "\n",
    "def naive_solve(n_generate_sample, prompt_sample, task, idx, to_print=True):\n",
    "    # breakpoint()\n",
    "    x = task.get_input(idx)  # input\n",
    "    ys = get_samples(task, x, '', n_generate_sample, prompt_sample, stop=None) # Get generated output from LLM \n",
    "    return ys, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a245b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'llama-7B'\n",
    "temperature = 0.7\n",
    "naive_run = False\n",
    "task = 'game24' # 'game24' | 'text' | 'crosswords'\n",
    "task_file_path = '24.csv'\n",
    "task_start_index = 100\n",
    "task_end_index = 101\n",
    "method_generate = 'propose'\n",
    "method_evaluate = 'value'\n",
    "method_select = 'greedy'\n",
    "n_evaluate_sample = 3\n",
    "n_select_sample = 5\n",
    "n_generate_sample = 100\n",
    "prompt_sample = 'cot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90031102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 24.csv\n",
      "-- new_ys --: ('4 + 5 = 9 (left: 9 11 12)\\n', '5 - 4 = 1 (left: 1 5 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n', '11 /  2 = 5.5 (left: 5.5\\n')\n",
      "-- sol values --: (0.002, 0.0, 0.0, 0.0, 0.0)\n",
      "-- choices --: ['4 + 5 = 9 (left: 9 11 12)\\n', '5 - 4 = 1 (left: 1 5 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n', '11 /  2 = 5.5 (left: 5.5\\n']\n",
      "\n",
      "-- new_ys --: ('5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n', '11 + 1 = 12 (left: 12 1 11)\\n12 /  1 = 12 (\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 / 12 =\\n', '11 /  2 = 5.5 (left: 5.5\\n5.5 + 5.5 = 11.5 (left: 11.5 5.5)\\n', '11 /  2 = 5.5 (left: 5.5\\n1 +\\n', '4 + 5 = 9 (left: 9 11 12)\\n9 + 11 = 20 (left: 12 20)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11 - 9 = 2 (left: 20 2)\\n', '4 + 5 = 9 (left: 9 11 12)\\n12 - 11 = 1 (left: 20 1)\\n', '4 + 5 = 9 (left: 9 11 12)\\n12 /  2 = 6 (left: 1 6 20)\\n', '4 + 5 = 9 (left: 9 11 12)\\n12 - 1 = 11 (left: 1 6 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n1 + 5 = 6 (left: 6 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n5 / 1 = 5 (left: 5 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 /  1 = 11 (left: 11 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n12 + 1 = 13 (left: 13 1 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n12 / 1 = 12 (left: 12 1 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n11 + 1 = 12 (left: 12 12 11)\\n', '11 + 1 = 12 (left: 12 1 11)\\n12 - 1 = 11 (left: 11 12 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n12 - 11 = 1 (left: 11 12 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 - 12 = -1 (left: 12 11 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 * 12 = 132 (left: 12 132 1)\\n', '11 /  2 = 5.5 (left: 5.5\\n11.5 - 5.5 = 6 (left: 6 11.5)\\n', '11 /  2 = 5.5 (left: 5.5\\n6 + 5.5 = 6.5 (left: 6.5 5.5)\\n', '11 /  2 = 5.5 (left: 5.5\\n6.5 - 5.5 = 1 (left: 1 6.5)\\n')\n",
      "-- sol values --: (0.003, 0.003, 0.002, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "-- choices --: ['5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n']\n",
      "\n",
      "-- new_ys --: ('5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n12 + 11 = 23 (left: 12 23 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n12 - 11 = 1 (left: 11 12 1)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n12 * 11 = 121 (left: 121 11 12)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 + 1 = 12 (left: 12 11)\\n12 / 11 = 1.09 (left: 1.09 11 12)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = 1 (left: 1 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 * 11 = 110 (left: 110 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 / 11 = 0.9 (left: 0.9 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = -1 (left: -1\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 - 23 = -11 (left: 12 11 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 * 23 = 276 (left: 276 12 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 / 23 = 0.526 (left: 0.526 12 1)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 /  1 = 11 (left: 11 11)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 10)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 /  1 = 11 (left: 11 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n')\n",
      "-- sol values --: (0.003, 0.003, 0.003, 0.003, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0)\n",
      "-- choices --: ['5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n']\n",
      "\n",
      "-- new_ys --: ('4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 + 21 = 31 (left: 10 31)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 - 21 = -11 (left: -11 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 * 21 = 210 (left: 210 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 / 21 = 0.476190476 (left: 0.476190476\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n12 + 11 = 23 (left: 12 23 11)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n12 - 11 = 1 (left: 11 12 1)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n12 * 11 = 121 (left: 121 11 12)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 + 1 = 12 (left: 12 11)\\n12 / 11 = 1.09 (left: 1.09 11 12)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = 1 (left: 1 10)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 * 11 = 110 (left: 110 10)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 / 11 = 0.9 (left: 0.9 10)\\n', '4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = -1 (left: -1\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = 1 (left: 1 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 * 11 = 110 (left: 110 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 / 11 = 0.9 (left: 0.9 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 - 11 = -1 (left: -1\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n12 + 35 = 47 (left: 1 47 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n12 - 35 = -23 (left: 1 -23 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n12 * 35 = 420 (left: 12 420 1)\\n', '12 - 1 = 11 (left: 11 12 1)\\n11 + 12 = 23 (left: 12 23 1)\\n12 + 23 = 35 (left: 12 35 1)\\n12 / 35 = 0.346153846153846 (left: 0.\\n')\n",
      "-- sol values --: (0.003, 0.003, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0)\n",
      "-- choices --: ['4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 + 21 = 31 (left: 10 31)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 - 21 = -11 (left: -11 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 * 21 = 210 (left: 210 10)\\n']\n",
      "\n",
      "['4 + 5 = 9 (left: 9 11 12)\\n11\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 =\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 + 21 = 31 (left: 10 31)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 - 21 = -11 (left: -11 10)\\n', '5 - 4 = 1 (left: 1 5 11)\\n11 - 1 = 10 (left: 10 11)\\n10 + 11 = 21 (left: 10 21)\\n10 * 21 = 210 (left: 210 10)\\n']\n",
      "100 sum(accs) 0 cnt_avg 0.0 cnt_any 0 \n",
      "\n",
      "0.0 0.0\n",
      "usage_so_far {'completion_tokens': 0, 'prompt_tokens': 0, 'cost': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensures functions invoked using 'task' - an object of a Task class - are from their respective class where they are defined.\n",
    "task = get_task(task, task_file_path) # returns a task class object (e.g., Game24Task class in tasks/game24.py) returned by get_task() which is imported as a function from __init__.py, which takes in args.task (identifier of task entered in the cli) and returns an instantiated object of a task class e.g., Game24Task class obj in tasks/game24.py\n",
    "logs, cnt_avg, cnt_any = [], 0, 0\n",
    "\n",
    "# breakpoint()\n",
    "if naive_run: # create new directory and file name to store generated data\n",
    "    file = f'logs/{task}/{backend}_{temperature}_naive_{prompt_sample}_sample_{n_generate_sample}_start{task_start_index}_end{task_end_index}.json'\n",
    "else:\n",
    "    file = f'logs/{task}/{backend}_{temperature}_{method_generate}{n_generate_sample}_{method_evaluate}{n_evaluate_sample}_{method_select}{n_select_sample}_start{task_start_index}_end{task_end_index}.json'\n",
    "os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "\n",
    "for i in range(task_start_index, task_end_index):\n",
    "\n",
    "    # breakpoint()\n",
    "    # solve: choosing between standard prompting, CoT, ToT\n",
    "    if naive_run: # naive run happens to all standard.* and cot prompts,\n",
    "        ys, info = naive_solve(n_generate_sample, prompt_sample, task, idx=i, to_print=True)\n",
    "    else:\n",
    "        ys, info = solve(method_generate, n_generate_sample,\n",
    "          prompt_sample, method_evaluate,\n",
    "          method_select, n_select_sample,\n",
    "          task, idx=i, to_print=True)\n",
    "\n",
    "    # Appends a dictionary to logs \n",
    "    # log \n",
    "    infos = [task.test_output(i, y) for y in ys] # test_output() for each task are defined in ./task/* \n",
    "\n",
    "   # Replaced with llama_usage\n",
    "    info.update({'idx': i, 'ys': ys, 'infos': infos, 'usage_so_far': LLM.llama_usage(backend)})\n",
    "\n",
    "    logs.append(info)\n",
    "    with open(file, 'w') as f:\n",
    "        json.dump(logs, f, indent=4)\n",
    "\n",
    "    # log main metric\n",
    "    accs = [info['r'] for info in infos]\n",
    "    cnt_avg += sum(accs) / len(accs)\n",
    "    cnt_any += any(accs)\n",
    "    print(i, 'sum(accs)', sum(accs), 'cnt_avg', cnt_avg, 'cnt_any', cnt_any, '\\n')\n",
    "\n",
    "n = task_end_index - task_start_index\n",
    "print(cnt_avg / n, cnt_any / n)\n",
    "\n",
    "# print('usage_so_far', gpt_usage(args.backend))\n",
    "\n",
    "# Replaced with llama_usage\n",
    "print('usage_so_far', LLM.llama_usage(backend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf593b",
   "metadata": {},
   "source": [
    "TODO: formatting in jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wscot",
   "language": "python",
   "name": "wscot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
